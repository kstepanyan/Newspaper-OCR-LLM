{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- Processing pages/Pi-Newspaper-1978-1.jpg -----\n",
      "✅  Saved extraction to extractions/Pi-Newspaper-1978-1.json\n",
      "Processing time  pages/Pi-Newspaper-1978-1.jpg: 40.4992 seconds\n"
     ]
    }
   ],
   "source": [
    "# The code is traversing the input directories and processing all images for OCR.\n",
    "# The prompt used in the code was automatically optimised in OpenAI Playground.\n",
    "\n",
    "import glob\n",
    "import base64\n",
    "import time\n",
    "from openai import OpenAI\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 1. Set up client and the saved prompt reference you supplied\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "client = OpenAI(api_key=\"ADD_YOUR_API_KEY_HERE\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# 2. Set up input and output paths\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "input_path = Path(\"pages\")                              # folder with JPGs\n",
    "output_path = input_path.parent / \"extractions\"        # sibling of \"pages\" (NOT named \"articles\")\n",
    "output_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Utility helpers\n",
    "# ---------------------------------------------------------------------\n",
    "\n",
    "def encode_image(input_path: str) -> str:\n",
    "    \"\"\"Return a Base‑64 data URL for the JPG so it can be sent inline.\"\"\"\n",
    "    with open(input_path, \"rb\") as image_file:\n",
    "        img_b64 = base64.b64encode(image_file.read()).decode(\"utf-8\")\n",
    "    return f\"data:image/jpeg;base64,{img_b64}\"\n",
    "\n",
    "\n",
    "def extract_text_from_completion(comp_msg) -> str | None:\n",
    "    \"\"\"Return the assistant's textual reply independent of the format it came in.\n",
    "\n",
    "    • If the model answered with a plain string → return it.\n",
    "    • If the model answered with a list of content parts → join the *text* parts.\n",
    "    • Otherwise → None (signals a retry).\n",
    "    \"\"\"\n",
    "    # Case A – plain string already present\n",
    "    if isinstance(comp_msg.content, str) and comp_msg.content.strip():\n",
    "        return comp_msg.content\n",
    "\n",
    "    # Case B – rich‑content list (e.g. [{\"type\":\"text\", ...}, {\"type\":\"image_url\", ...}])\n",
    "    if isinstance(comp_msg.content, list):\n",
    "        pieces: list[str] = []\n",
    "        for part in comp_msg.content:\n",
    "            # The OpenAI Python client uses dicts for multimodal parts\n",
    "            if isinstance(part, dict) and part.get(\"type\") == \"text\":\n",
    "                pieces.append(part.get(\"text\", \"\"))\n",
    "            # Future‑proof: the object may expose .text directly (pydantic models)\n",
    "            elif hasattr(part, \"text\"):\n",
    "                pieces.append(getattr(part, \"text\"))\n",
    "        joined = \"\".join(pieces).strip()\n",
    "        return joined or None\n",
    "\n",
    "    # Anything else – treat as failure\n",
    "    return None\n",
    "\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are an expert in careful and accurate extraction of text from historical newspapers. \\n\\n\"\n",
    "    \"Extract individual articles from the given page of a newspaper issue.\\n\\n\"\n",
    "    \"## Output Format\\n\"\n",
    "    \"Return a JSON array containing objects for each extracted article. Each article object must include the following fields:\\n\"\n",
    "    \"- \\\"id\\\": a unique identifier for the article (e.g., sequential number or generated ID)\\n\"\n",
    "    \"- \\\"title\\\": the article's title (string, or null if not available)\\n\"\n",
    "    \"- \\\"author\\\": the author of the article (string, or null if not available)\\n\"\n",
    "    \"- \\\"date\\\": date of publication (string in YYYY-MM-DD format, or null if not available)\\n\"\n",
    "    \"- \\\"content\\\": full extracted text of the article\\n\"\n",
    "    \"- \\\"continues-to\\\": no, or page and column number on which the article continues.\\n\"\n",
    "    \"- \\\"continues-from\\\": no, or page and column number from where the article continues.\\n\"\n",
    "    \"- \\\"metadata\\\": an object with any additional extracted metadata (may be empty)\\n\"\n",
    "    \"- \\\"errors\\\": an array of issues or ambiguities if any occurred during extraction (empty array if none)\\n\\n\"\n",
    "    \"If an article cannot be confidently separated, or if OCR/extraction failures occur, include an \\\"errors\\\" array within the relevant article object, listing the nature of ambiguities or extraction issues.\\n\\n\"\n",
    "    \"Example output:\\n\"\n",
    "    \"[\\n\"\n",
    "    \"  {\\n\"\n",
    "    \"    \\\"id\\\": \\\"1\\\",\\n\"\n",
    "    \"    \\\"title\\\": \\\"Breaking News in Boston\\\",\\n\"\n",
    "    \"    \\\"author\\\": \\\"Jane Doe\\\",\\n\"\n",
    "    \"    \\\"date\\\": \\\"1912-07-14\\\",\\n\"\n",
    "    \"    \\\"content\\\": \\\"Full article text goes here...\\\",\\n\"\n",
    "    \"    \\\"continues-to\\\": \\\"no\\\",\\n\"\n",
    "    \"    \\\"continues-from\\\": \\\"no\\\",\\n\"\n",
    "    \"    \\\"metadata\\\": {\\\"section\\\": \\\"Front Page\\\"},\\n\"\n",
    "    \"    \\\"errors\\\": []\\n\"\n",
    "    \"  },\\n\"\n",
    "    \"  {\\n\"\n",
    "    \"    \\\"id\\\": \\\"2\\\",\\n\"\n",
    "    \"    \\\"title\\\": null,\\n\"\n",
    "    \"    \\\"author\\\": null,\\n\"\n",
    "    \"    \\\"date\\\": null,\\n\"\n",
    "    \"    \\\"content\\\": \\\"Article text mixed with an image and difficult to separate...\\\",\\n\"\n",
    "    \"    \\\"continues-to\\\": \\\"page 3, column 2\\\",\\n\"\n",
    "    \"    \\\"continues-from\\\": \\\"page 1, column 1\\\",\\n\"\n",
    "    \"    \\\"metadata\\\": {},\\n\"\n",
    "    \"    \\\"errors\\\": [\\\"Unable to confidently extract boundaries due to OCR artifacts.\\\"]\\n\"\n",
    "    \"  }\\n\"\n",
    "    \"]\"\n",
    ")\n",
    "\n",
    "user_prompt = \"You are analyzing a historical newspaper called Pi. It is scanned page comes from the newspaper issue as a JPG. Each image contains multiple articles that span multi-colum layout. Your task is to extract each of the individual articles from the JPG file. Some articles may continue to other columns make sure the text that spans multiple columns but belongs to the same article is extracted as a single article. Indicate which article continues on another page, if this is seen. Return a JSON object with a single key 'articles', whose value is an array of article objects. All articles must be extracted from each page. Only read the content from the newspaper page as is, and do not add or embelish the content.\"\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Core routine\n",
    "# ----------------------------------------------------------------------\n",
    "def process_image(image_path: Path, input_root: Path, output_root: Path, max_retries: int = 2) -> None:\n",
    "    \"\"\"Send image_path to the model and save JSON into a mirrored path under output_root.\"\"\"\n",
    "    # Compute mirrored output locations (preserve subfolders)\n",
    "    rel = image_path.relative_to(input_root)\n",
    "    json_out = (output_root / rel).with_suffix(\".json\")\n",
    "    err_out  = (output_root / rel).with_suffix(\".error.txt\")\n",
    "    json_out.parent.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    for attempt in range(1, max_retries + 2):  # first try + retries\n",
    "        data_url = encode_image(image_path)\n",
    "        completion = client.chat.completions.create(\n",
    "            model=\"o4-mini-2025-04-16\",\n",
    "            response_format={\"type\": \"json_object\"},\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": system_prompt},\n",
    "                {\"role\": \"user\", \"content\": [\n",
    "                    {\"type\": \"text\", \"text\": user_prompt},\n",
    "                    {\"type\": \"image_url\", \"image_url\": {\"url\": data_url}},\n",
    "                ]},\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        msg = completion.choices[0].message\n",
    "        json_content = extract_text_from_completion(msg)\n",
    "\n",
    "        if json_content:\n",
    "            json_out.write_text(json_content, encoding=\"utf-8\")\n",
    "            print(f\"✅  Saved extraction to {json_out}\")\n",
    "            return\n",
    "\n",
    "        # Retry logic\n",
    "        if attempt <= max_retries:\n",
    "            print(f\"⚠️  No textual content for {image_path} (attempt {attempt}). Retrying …\")\n",
    "            time.sleep(1.5)\n",
    "        else:\n",
    "            err_out.write_text(\n",
    "                \"Assistant returned no textual parts after multiple attempts.\",\n",
    "                encoding=\"utf-8\",\n",
    "            )\n",
    "            print(f\"❌  Failed after {max_retries + 1} attempts. Details → {err_out}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# Batch runner\n",
    "# ----------------------------------------------------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    image_paths = sorted(input_path.rglob(\"*.jpg\"))\n",
    "    for img_path in image_paths:\n",
    "        tic = time.perf_counter()\n",
    "        print(f\"----- Processing {img_path} -----\")\n",
    "        process_image(img_path, input_path, output_path)\n",
    "        toc = time.perf_counter()\n",
    "        print(f\"Processing time  {img_path}: {toc - tic:0.4f} seconds\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
